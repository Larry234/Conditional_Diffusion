{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8553ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from utils import get_model, LoadEncoder\n",
    "from models.engine import TripleCondDDIMSampler\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "859b26bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(argparse.Namespace):\n",
    "    arch = \"unetattentiontriple\"\n",
    "    img_size=64\n",
    "    num_timestep = 1000\n",
    "    beta = (0.0001, 0.02)\n",
    "    num_condition = [2, 2, 4]\n",
    "    emb_size = 128\n",
    "    channel_mult = [1, 2, 2, 2]\n",
    "    num_res_blocks = 2\n",
    "    use_spatial_transformer = True\n",
    "    num_heads = 4\n",
    "    num_sample_missing = 50\n",
    "    num_sample = 5\n",
    "    w = 1.8\n",
    "    projection_dim=512\n",
    "    only_table = False\n",
    "    concat = False\n",
    "    only_encoder = False\n",
    "    num_head_channels = -1\n",
    "    encoder_path = None\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86a785f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All keys successfully match\n"
     ]
    }
   ],
   "source": [
    "model = get_model(args)\n",
    "\n",
    "ckpt = torch.load(\"checkpoints/Zappo50KTriple/HeelSandalCA/model_100.pth\")[\"model\"]\n",
    "new_dict = OrderedDict()\n",
    "    \n",
    "for k, v in ckpt.items():\n",
    "    if k.startswith(\"module\"):\n",
    "        new_dict[k[7:]] = v\n",
    "    else:\n",
    "        new_dict[k] = v\n",
    "try:\n",
    "    model.load_state_dict(new_dict)\n",
    "    print(\"All keys successfully match\")\n",
    "except:\n",
    "    print(\"some keys are missing!\")\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "sampler = TripleCondDDIMSampler(\n",
    "    model=model,\n",
    "    beta =args.beta,\n",
    "    T=args.num_timestep,\n",
    "    w=args.w,\n",
    ").to(device)\n",
    "\n",
    "# if args.encoder_path != None:\n",
    "#     encoder = LoadEncoder(args).to(device)\n",
    "#     sampler = DDIMSamplerEncoder(\n",
    "#             model = model,\n",
    "#             encoder = encoder,\n",
    "#             beta = args.beta,\n",
    "#             T = args.num_timestep,\n",
    "#             w = args.w,\n",
    "#             only_encoder = args.only_encoder\n",
    "#     ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb1cc27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;101;101;181m██████████\u001b[0m| 100/100 [00:09<00:00, 10.22it/s, step=1, sample=1]\n",
      "100%|\u001b[38;2;101;101;181m██████████\u001b[0m| 100/100 [00:10<00:00,  9.75it/s, step=1, sample=1]\n",
      "100%|\u001b[38;2;101;101;181m██████████\u001b[0m| 100/100 [00:09<00:00, 10.25it/s, step=1, sample=1]\n",
      "100%|\u001b[38;2;101;101;181m██████████\u001b[0m| 100/100 [00:09<00:00, 10.00it/s, step=1, sample=1]\n",
      "100%|\u001b[38;2;101;101;181m██████████\u001b[0m| 100/100 [00:09<00:00, 10.00it/s, step=1, sample=1]\n",
      "100%|\u001b[38;2;101;101;181m██████████\u001b[0m| 100/100 [00:09<00:00, 10.41it/s, step=1, sample=1]\n",
      "100%|\u001b[38;2;101;101;181m██████████\u001b[0m| 100/100 [00:09<00:00, 10.56it/s, step=1, sample=1]\n",
      "100%|\u001b[38;2;101;101;181m██████████\u001b[0m| 100/100 [00:09<00:00, 10.58it/s, step=1, sample=1]\n",
      "100%|\u001b[38;2;101;101;181m██████████\u001b[0m| 100/100 [00:09<00:00, 10.38it/s, step=1, sample=1]\n",
      "100%|\u001b[38;2;101;101;181m██████████\u001b[0m| 100/100 [00:09<00:00, 10.45it/s, step=1, sample=1]\n",
      "100%|\u001b[38;2;101;101;181m██████████\u001b[0m| 100/100 [00:09<00:00, 10.43it/s, step=1, sample=1]\n",
      "100%|\u001b[38;2;101;101;181m██████████\u001b[0m| 100/100 [00:09<00:00, 10.54it/s, step=1, sample=1]\n",
      "100%|\u001b[38;2;101;101;181m██████████\u001b[0m| 100/100 [00:09<00:00, 10.50it/s, step=1, sample=1]\n",
      "100%|\u001b[38;2;101;101;181m██████████\u001b[0m| 100/100 [00:09<00:00, 10.52it/s, step=1, sample=1]\n"
     ]
    }
   ],
   "source": [
    "from config import Zappo50KTriple, TripleCond\n",
    "\n",
    "CFG = Zappo50KTriple()\n",
    "\n",
    "missings = [\"Right Heel Sandal\", \"Left Heel Sandal\"]\n",
    "targets = [\n",
    "    \"Right Flat Boot\", \"Right Flat Shoe\", \"Right Flat Slipper\", \"Right Flat Sandal\", \"Right Heel Boot\", \"Right Heel Shoe\", \"Right Heel Slipper\",\n",
    "    \"Left Flat Boot\", \"Left Flat Shoe\", \"Left Flat Slipper\", \"Left Flat Sandal\", \"Left Heel Boot\", \"Left Heel Shoe\", \"Left Heel Slipper\"\n",
    "]\n",
    "# missing = \"Gray_Hair Female\"\n",
    "# targets = [\"Brown_Hair Male\", \"Black_Hair Male\", \"Gray_Hair Male\", \"Blond_Hair Male\", \"Brown_Hair Female\", \"Black_Hair Female\", \"Blond_Hair Female\"]\n",
    "\n",
    "# images = []\n",
    "# for missing in missings:\n",
    "#     size, atr, obj = CFG.SIZE2IDX[missing.split(\" \")[0]], CFG.ATR2IDX[missing.split(\" \")[1]], CFG.OBJ2IDX[missing.split(\" \")[-1]]\n",
    "#     size = torch.tensor(size, dtype=torch.long, device=device).repeat(args.num_sample_missing)\n",
    "#     atr = torch.tensor(atr, dtype=torch.long, device=device).repeat(args.num_sample_missing)\n",
    "#     obj = torch.tensor(obj, dtype=torch.long, device=device).repeat(args.num_sample_missing)\n",
    "#     x_i = torch.randn(args.num_sample_missing, 3, 64, 64).to(device)\n",
    "#     x0 = sampler(x_i, size, atr, obj, steps=100)\n",
    "#     x0 = x0 * 0.5 + 0.5\n",
    "#     images.append(x0)\n",
    "\n",
    "# images = torch.concatenate(images, dim=0)\n",
    "# save_image(images, \"SampledImg/TripleCond/HeelSandalCA.png\", nrow=10, noramlized=True)\n",
    "\n",
    "images = []\n",
    "for target in targets:\n",
    "    size, atr, obj = CFG.SIZE2IDX[target.split(\" \")[0]], CFG.ATR2IDX[target.split(\" \")[1]], CFG.OBJ2IDX[target.split(\" \")[-1]]\n",
    "    size = torch.tensor(size, dtype=torch.long, device=device).repeat(args.num_sample)\n",
    "    atr = torch.tensor(atr, dtype=torch.long, device=device).repeat(args.num_sample)\n",
    "    obj = torch.tensor(obj, dtype=torch.long, device=device).repeat(args.num_sample)\n",
    "\n",
    "    x_i = torch.randn(args.num_sample, 3, 64, 64).to(device)\n",
    "    x0 = sampler(x_i, size, atr, obj, steps=100)\n",
    "    x0 = x0 * 0.5 + 0.5\n",
    "    images.append(x0)\n",
    "    \n",
    "images = torch.concatenate(images, dim=0)\n",
    "# images = make_grid(images, nrow=args.num_sample)\n",
    "save_image(images, \"SampledImg/TripleCond/SeenCA.png\", nrow=10, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d18bef75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Flat Boot\n",
      "Right Flat Shoe\n",
      "Right Flat Slipper\n",
      "Right Flat Sandal\n",
      "Right Heel Boot\n",
      "Right Heel Shoe\n",
      "Right Heel SlipperLeft Flat Boot\n",
      "Left Flat Shoe\n",
      "Left Flat Slipper\n",
      "Left Flat Sandal\n",
      "Left Heel Boot\n",
      "Left Heel Shoe\n",
      "Left Heel Slipper\n"
     ]
    }
   ],
   "source": [
    "for t in targets:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc9bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conditional_Diffusion",
   "language": "python",
   "name": "conditional_diffusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
